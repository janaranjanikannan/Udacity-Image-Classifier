{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "#from workspace_utils import active_session\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "def get_data(data_dir):\n",
    "    train_dir = data_dir + '/train'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    test_dir = data_dir + '/test'\n",
    "    \n",
    "    # Define transforms for the training, validation, and testing sets\n",
    "    train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "    validate_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "    # Load the datasets with ImageFolder\n",
    "    train_datasets = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    validate_datasets = datasets.ImageFolder(valid_dir, transform=validate_transforms)\n",
    "    test_datasets = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "    # Using the image datasets and the trainforms, define the dataloaders\n",
    "    trainloader = torch.utils.data.DataLoader(train_datasets, batch_size=64, shuffle=True)\n",
    "    validateloader = torch.utils.data.DataLoader(validate_datasets, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(test_datasets, batch_size=64)\n",
    "\n",
    "    return trainloader, validateloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_size=1024, output_size=102, hidden_units=512, drop_p=0.5,arch='densenet121'):        \n",
    "\n",
    "    model = eval(\"models.{}(pretained=True)\".format(arch))\n",
    "    \n",
    "    for params in model.parameters():\n",
    "        params.requires_grad= False\n",
    "    \n",
    "    model.classifier = nn.Sequential(nn.Linear(input_size,hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=drop_p),\n",
    "                                 nn.Linear(hidden_units,output_size),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimizer(model,learning_rate=0.003):\n",
    "    return optim.Adam(model.classifier.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the network\n",
    "def train_network(model, trainloader, validateloader, criterion, optimizer, epochs=5, print_every=40,device='cpu'):\n",
    "    steps = 0\n",
    "    train_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model.forward(images)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                validate_loss = 0\n",
    "                validate_accuracy = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in validateloader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        log_ps = model.forward(images)\n",
    "                        loss = criterion(log_ps, labels)\n",
    "\n",
    "                        validate_loss += loss.item()\n",
    "\n",
    "                        # Calculate accuracy\n",
    "                        ps = torch.exp(log_ps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        validate_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Train loss: {train_loss/print_every:.3f}.. \"\n",
    "                      f\"Validation loss: {validate_loss/len(validateloader):.3f}.. \"\n",
    "                      f\"Validation accuracy: {validate_accuracy/len(validateloader):.3f}\")\n",
    "                train_loss = 0\n",
    "                model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,optimizer,save_dir='.',train_datasets,input_size=1024, output_size=102, hidden_units=512,epochs=5):\n",
    "    model.class_to_idx = train_datasets.class_to_idx\n",
    "\n",
    "    checkpoint = {'input_size': input_size,\n",
    "                  'hidden_units': hidden_units\n",
    "                  'output_size': output_size,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'classes_indices_map': model.class_to_idx,\n",
    "                  'epoch': epochs}\n",
    "\n",
    "    model_checkpoint=save_dir+'/checkpoint.pth'\n",
    "    torch.save(checkpoint, model_checkpoint)\n",
    "    return model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--save_dir SAVE_DIR] [--arch ARCH]\n",
      "                             [--lrn LRN] [--hidden_units HIDDEN_UNITS]\n",
      "                             [--epochs EPOCHS] [--GPU GPU]\n",
      "                             data_dir\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balaranji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define Command Line arguments for the script\n",
    "    parser = argparse.ArgumentParser (description = \"Train a new network on a dataset and save the model as a checkpoint\")\n",
    "\n",
    "    parser.add_argument ('data_dir', help = 'Provide data directory.', type = str)\n",
    "    parser.add_argument ('--save_dir', help = 'Optional: Provide saving directory. Default is current directory', type = str)\n",
    "    parser.add_argument ('--arch', help = 'Optional: Provide a Pretrained model. Default pretrained model is densenet121', type = str)\n",
    "    parser.add_argument ('--lrn', help = 'Optional: Learning rate. Default value is 0.003', type = float)\n",
    "    parser.add_argument ('--hidden_units', help = 'Optional: Hidden units in Classifier. Default value is 512', type = int)\n",
    "    parser.add_argument ('--epochs', help = 'Optional: Number of epochs. Default value is 5', type = int)\n",
    "    parser.add_argument ('--GPU', help = \"Optional: Option to use GPU. Default is CPU\", type = str)\n",
    "\n",
    "    #setting values data loading\n",
    "    args = parser.parse_args ()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
